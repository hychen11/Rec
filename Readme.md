https://www.yuque.com/yuejiangliu/recommended-system-in-the-industry/overview

# 概要

- 北极星指标 —— 衡量推荐系统好坏 —— 在小红书考虑下面 3 个

  - 用户规模：

    - 日活用户数（DAU）、月活用户数（MAU）

    - DAU：每天使用 1 次以上

    - MAU：每月使用 1 次以上

- 消费：
  - 人均使用推荐的时长、人均阅读笔记的数量

- 发布：
  - 发布渗透率、人均发布量

- 北极星指标 都是线上指标，只能上线了才能获得

### 链路

![img](https://cdn.nlark.com/yuque/0/2022/png/101969/1672040737013-f61fc9a3-6159-42d1-a84c-dfe6a798368a.png?x-oss-process=image%2Fformat%2Cwebp)

- 粗排：用到规模比较小的模型
- 精排：用到大规模深度神经网络，对 items 进行打分
- 召回通道：协同过滤、双塔模型、关注的作者等等
  - 小红书有几十个召回通道，每个通道返回几十上百篇笔记
  - 将所有召回通道的内容融合后，会去重，并过滤（例如去掉用户不喜欢的作者的笔记，不喜欢的话题）

- 排序： 排序： [几千] → 粗排 → [几百] → 精排 → [几百] → 重排 → [几十]
  - 粗排模型小，速度快；精排用的模型大，计算量大，打分更可靠
  - 用粗排做筛选，再用精排  —— 平衡计算量和准确性
  - 本来是可以用精排分数排序后直接推荐的，但此时的结果还存在一些不足（例如 多样性）
  - 重排根据多样性随机抽样，还要用规则将相似的笔记打散，还得把广告插进去
    - 重排做多样性抽样（比如 MMR、DPP），从几百篇中选出几十篇（抽样依据：精排分数、多样性）
    - 用规则打散相似笔记（不能把内容过于相似的笔记，排在相邻的位置上，减少同质化）（插入广告、运营推广内容，根据生态要求调整排序（例如 不能同时出很多美女图片））

![img](https://cdn.nlark.com/yuque/0/2022/png/101969/1672040737349-6f740342-0c22-4b24-ad95-96b9c49c463e.png?x-oss-process=image%2Fformat%2Cwebp)

总结

* 首先召回，多条通道取回几千篇笔记
* 再粗排，小规模nn打分选出top几百的（和召回都是大漏斗）
* 精排，大规模nn打分
* 重排：多样性抽样，规则打散，插入广告运营笔记

## A/B test

实现了一种 GNN 召回通道，离线实验结果正向

做线上的小流量 A/B 测试，考察新的召回通道对线上指标的影响

模型中有一些参数，比如 GNN 的深度取值 \in\{1,2,3\} ，需要用 A/B 测试选取最优参数

### 随机分桶

- 分 b = 10 个桶，每个桶中有 10% 的用户
- 首先用哈希函数把用户 ID 映射成某个区间内的整数，然后把这些整数均匀随机分成 b 个桶
- 全部 n 位用户，分成 b 个桶，每个桶中有 \frac{n}{b} 位用户

- 计算每个桶的业务指标，比如 DAU、人均使用推荐的时长、点击率、等等
- 如果某个实验组指标显著优于对照组，则说明对应的策略有效，值得推全

### 分层实验

流量不够用怎么办？

- 信息流产品的公司有很多部门和团队，大家都需要做 A/B 测试

  - 推荐系统（召回、粗排、精排、重排）

  - 用户界面

  - 广告

- 如果把用户随机分成 10 组，1 组做对照，9 组做实验，那么只能同时做 9 组实验

分层实验

- 分层实验：召回、粗排、精排、重排、用户界面、广告......（例如 GNN 召回通道属于召回层）
- 同层互斥：GNN 实验占了召回层的 4 个桶，其他召回实验只能用剩余的 6 个桶
- 不同层正交：每一层独立随机对用户做分桶。每一层都可以独立用 100% 的用户做实验



- **召回层（Recall）**：把用户分成 10 个桶 $\mathcal{U}_1, ..., \mathcal{U}_{10}$
- **精排层（Ranking）**：把用户也分成 10 个桶 $\mathcal{V}_1, ..., \mathcal{V}_{10}$

假设系统共有 $n$ 个用户：
$$
|\mathcal{U}_i| = |\mathcal{V}_j| = n/10
$$
也就是说，每个桶的用户数量相等。

### 召回桶之间互斥

$$
\mathcal{U}_i \cap \mathcal{U}_j = \emptyset \quad (i \ne j)
$$

- 这意味着**同一个用户不会同时参与两个不同召回实验**。

召回桶和精排桶的交集

### 桶的交集

$$
|\mathcal{U}_i \cap \mathcal{V}_j| = n/100
$$

- 总用户数 $n$ 分成 10 个召回桶和 10 个精排桶，交集大小正好是 $n / (10 \times 10) = n/100$
- **解释**：
  - 一个用户不能同时受两个召回实验的影响，但可以同时受一个召回实验 + 一个精排实验的影响

### Holdout 机制

10% holdout 桶 vs 90% 实验桶的 diff（需要归一化）为整个部门的业务指标收益

![img](https://cdn.nlark.com/yuque/0/2022/png/101969/1672040737752-8f9a1928-de50-4842-b73f-cff013f466fe.png?x-oss-process=image%2Fformat%2Cwebp)

holdout 桶里面不加任何新的实验，保持干净以便对照

每个考核周期结束之后，清除 holdout 桶，让推全实验从 90% 用户扩大到 100% 用户

```
整个用户群
├── Holdout (10%)：不参与实验，baseline
└── 实验用户 (90%)
     ├── 原有层（旧策略）
     └── 新推全层（正交）
           ├── 新策略大部分用户
           └── 反转桶（小部分用户，仍用旧策略）
```

# 召回

### ItemCF (Item Collaboration Filter)

维护两个索引：`user-> list<item> `, `item->topK similar item`

![img](https://cdn.nlark.com/yuque/0/2022/png/101969/1672042313418-03a5b3e6-a546-4f8c-a8e3-790a35fe90e5.png?x-oss-process=image%2Fformat%2Cwebp)

1. **余弦相似度**：

$$
sim(i,j) = \frac{|U_i \cap U_j|}{\sqrt{|U_i|\cdot |U_j|}}
$$

公式没有考虑喜欢的程度 𝑙𝑖𝑘𝑒(𝑢𝑠𝑒𝑟, 𝑖𝑡𝑒𝑚)，即喜欢就是 1，不喜欢就是 0

如果用户喜欢 A，那么他也可能喜欢与 A 相似的物品 B

1. 找出用户已经喜欢过的物品集合 $I_u$
2. 对每个已喜欢的物品 $i \in I_u$，找出最相似的物品集合
3. 计算推荐得分：

$$
score(u, j) = \sum_{i \in I_u} sim(i, j)
$$

4. 将得分最高的topK物品推荐给用户

事先做离线计算

建立“用户 → 物品”的索引

- 记录每个用户最近点击、交互过的物品 ID
- 给定任意用户 ID，可以找到他近期感兴趣的物品列表

建立“物品 → 物品”的索引

- 计算物品之间两两相似度
- 对于每个物品，索引它最相似的 k 个物品
- 给定任意物品 ID，可以快速找到它最相似的 k 个物品

线上做召回

1. 给定用户 ID，通过“用户 → 物品”索引，找到用户近期感兴趣的物品列表（last-n）
2. 对于 last-n 列表中每个物品，通过“物品 → 物品”的索引，找到 top-k 相似物品
3. 对于取回的相似物品（最多有 𝑛𝑘 个），用公式预估用户对物品的兴趣分数
4. 返回分数最高的 100 个物品，作为推荐结果

索引的意义在于避免枚举所有的物品。用索引，离线计算量大，线上计算量小

1. 记录用户最近感兴趣的 n=200 个物品
2. 取回每个物品最相似的 k=10 个物品
3. 给取回的 nk=2000 个物品打分（用户对物品的兴趣）
4. 返回分数最高的 100 个物品作为 ItemCF 通道的输出

### Swing

Swing 和 ItemCF 很像，唯一区别在于如何定义相似度

ItemCF的问题

- 下图中两篇笔记被碰巧分享到了一个微信群里面
- 造成问题：两篇笔记的受众完全不同，但很多用户同时交互过这两篇笔记，导致系统错误判断两篇笔记相似度很高

- 想要解决该问题，就要降低小圈子用户的权重
- 如果大量不相关的用户同时交互两个物品，则说明两个物品的受众真的相同

两个物品的相似度：$sim(i_1,i_2)=\sum_{u_1\in \mathcal{V}}\sum_{u_2\in \mathcal{V}}\frac{1}{α+overlap(u_1,u_2)}$

- α 是超参数
- $overlap(u_1,u_2)$ 表示两个用户的重合度

- 重合度高，说明两人是一个小圈子的，那么他两对物品相似度的贡献就比较小
- 重合度小，两人不是一个小圈子的，他两对物品相似度的贡献就比较大

ItemCF：两个物品重合的用户比例高，则判定两个物品相似

Swing：额外考虑重合的用户是否来自一个小圈子

- 同时喜欢两个物品的用户记作集合 \mathcal{V}
- 对于 \mathcal{V} 中的用户 u_1 和 u_2，重合度记作 overlap(u_1,u_2)
- 两个用户重合度大，则可能来自一个小圈子，权重降低

### UserCF

先找相似用户，再推荐他们喜欢的物品给目标用户

推荐系统如何找到跟我兴趣非常相似的网友呢？

- 方法一：点击、点赞、收藏、转发的笔记有很大的重合
- 方法二：关注的作者有很大的重合

预估用户对候选物品的兴趣：$\sum_jsim(user,user_j)×like(user_j,item)$

计算用户相似度

- 用户 u_1 喜欢的物品记作集合 \mathcal{J}_1
- 用户 u_2 喜欢的物品记作集合 \mathcal{J}_2
- 定义交集 I=\mathcal{J}_1\cap\mathcal{J}_2
- 两个用户的相似度：$sim(u_1,u_2)=\frac{|I|}{\sqrt{|\mathcal{J}_1|·|\mathcal{J}_2|}}$

越热门的物品，越无法反映用户独特的兴趣，对计算用户相似度越没有价值，降低热门物品权重

- $n_l$：喜欢物品 l 的用户数量，反映物品的热门程度
- 物品越热门，$\frac{1}{\log{(1+n_l)}}$ 越小，对相似度的贡献就越小

#### 事先做离线计算

建立“用户 → 物品”的索引

- 记录每个用户最近点击、交互过的物品 ID
- 给定任意用户 ID，可以找到他近期感兴趣的物品列表

建立“用户 → 用户”的索引

- 对于每个用户，索引他最相似的 k 个用户
- 给定任意用户 ID，可以快速找到他最相似的 k 个用户

线上做召回

1. 给定用户 ID，通过“用户 → 用户”索引，找到 top-k 相似用户
2. 对于每个 top-k 相似用户，通过“用户 → 物品”索引，找到用户近期感兴趣的物品列表（last-n）
3. 对于取回的 nk 个相似物品，用公式预估用户对每个物品的兴趣分数
4. 返回分数最高的 100 个物品，作为召回结果

### 离散特征处理

离散特征处理的步骤

- 建立字典：把类别映射成序号
- 向量化：把序号映射成向量
  - One-hot 编码：把序号映射成高维稀疏向量（向量中只有 0，1） (类别数量太大时，通常不用 one-hot 编码)
  - Embedding：把序号映射成低维稠密向量（向量中有小数）（参数以矩阵的形式保存，矩阵大小是 向量维度 × 类别数量）

### 矩阵补充

#### 训练

基本想法

- 用户 embedding 参数矩阵记作 $\bold{A}$。第 u 号用户对应矩阵第 u 列，记作向量 $\bold{a}_u$
- 物品 embedding 参数矩阵记作 $\bold{B}$。第 i 号物品对应矩阵第 i 列，记作向量 $\bold{b}_i$
- 内积$ \left\langle \bold{a}_u,\bold{b}_i \right\rangle$ 是第 u 号用户对第 i 号物品兴趣的预估值
- 训练模型的目的是学习矩阵 \bold{A} 和 \bold{B}，使得预估值拟合真实观测的兴趣分数

数据集

- 数据集：（用户 ID，物品 ID，真实兴趣分数）的集合，记作 $\Omega=\{(u,i,y) \}$

- 数据集中的兴趣分数是系统记录的，比如：

  - 曝光但是没有点击 → 0 分

  - 点击、点赞、收藏、转发 → 各算 1 分

  - 分数最低是 0，最高是 4

- 训练的目的就是让模型的输出拟合真实兴趣分数

训练

- 把用户 ID、物品 ID 映射成向量。

  - 第 u 号用户 → 向量 $\bold{a}_u$

  - 第 i 号物品 → 向量 $\bold{b}_i$

![img](https://cdn.nlark.com/yuque/0/2022/png/101969/1672042316018-1bf99117-9105-4290-9997-5fd589d5ba94.png?x-oss-process=image%2Fformat%2Cwebp)

- 矩阵中只有少数位置是绿色，大多数位置是灰色（即大部分物品没有曝光给用户）
- 而我们用绿色位置训练出的模型，可以预估所有灰色位置的输出，即把矩阵的元素补全
- 把矩阵元素补全后，我们只需选出对应用户一行中分数较高的 物品 推荐给 用户 即可

缺点

- 仅用 ID embedding，没利用物品、用户属性

  - 物品属性：类目、关键词、地理位置、作者信息

  - 用户属性：性别、年龄、地理定位、感兴趣的类目

  - 双塔模型可以看做矩阵补充的升级版

  - 双塔模型不仅使用 ID，还结合各种属性

- 负样本的选取方式不对

  - 样本：用户—物品的二元组，记作 (u,i)
  - 正样本：曝光之后，有点击、交互。（正确的做法）
  - 负样本：曝光之后，没有点击、交互。（错误的做法）

  - 后面会专门用一节课时间讲正负样本如何选择

- 做训练的方法不好

  - 内积 $ \left\langle \bold{a}_u,\bold{b}_i \right\rangle$ 不如余弦相似度

  - 工业界普遍使用 余弦相似度 而不是 内积

  - 用平方损失（回归），不如用交叉熵损失（分类）

线上召回

- 把用户向量 \bold{a} 作为 query，查找使得  \left\langle \bold{a}_u,\bold{b}_i \right\rangle  最大化的物品 i
- 暴力枚举速度太慢。实践中用近似最近邻查找
- Milvus、Faiss、HnswLib 等向量数据库支持近似最近邻查找

### 双塔模型

**左塔（User Tower）**：输入用户的特征（用户ID、年龄、性别、历史行为序列、上下文信息等），输出用户的 embedding 向量 $\mathbf{u}$

**右塔（Item Tower）**：输入物品的特征（itemID、类目、价格、标题 embedding 等），输出物品的 embedding 向量 $\mathbf{v}$

通过内积或余弦相似度来衡量用户与物品的匹配程度：
$$
score(u, v) = \mathbf{u}^\top \mathbf{v}
$$
<img src="https://cdn.nlark.com/yuque/0/2022/png/101969/1672042316812-3bce2474-8eda-48cb-aa80-6f58bb78b238.png?x-oss-process=image%2Fformat%2Cwebp" alt="img" style="zoom:50%;" />

<img src="https://cdn.nlark.com/yuque/0/2022/png/101969/1672042316930-512c4448-5964-4bf2-9309-419cd3a16db5.png?x-oss-process=image%2Fformat%2Cwebp" alt="img" style="zoom:50%;" />

用户离散特征：例如所在城市、感兴趣的话题等

- 对每个离散特征，单独使用一个 Embedding 层得到一个向量
- 对于性别这种类别很少的离散特征，直接用 one-hot 编码

用户连续特征：年龄、活跃程度、消费金额等

- 双塔模型：左塔提取用户特征，右塔提取物品特征

- 与矩阵补充的区别在于，使用了除 ID 外的多种特征作为双塔的输入

#### 训练

- Pointwise：独立看待每个正样本、负样本，做简单的二元分类
- Pairwise：每次取一个正样本、一个负样本[1]
- Listwise：每次取一个正样本、多个负样本[2]

正负样本的选择

- 正样本：用户点击的物品

- 负样本[1, 2]：

  - 没有被召回的？

  - 召回但是被粗排、精排淘汰的？

  - 曝光但是未点击的？

  - 小红书选取负样本时，基本就参考了上面两篇论文[1, 2]

#### Pointwise 训练

- 把召回看做二元分类任务
- 对于正样本，鼓励 $\cos{(\bold{a},\bold{b})}$ 接近 +1
- 对于负样本，鼓励 $\cos{(\bold{a},\bold{b})}$$ 接近 −1
- 控制正负样本数量为 1: 2 或者 1: 3

#### Pairwise 训练

正样品，负样品都是相同nn参数的，cos(a,b+)大于 cos(a,b-)

- 如果  $\cos{(\bold{a},\bold{b}^+)}$ 大于 $\cos{(\bold{a},\bold{b}^-)}+m$，则没有损失

- m 是超参数，需要调

- 否则，损失等于  $\cos{(\bold{a},\bold{b}^-)}+m-\cos{(\bold{a},\bold{b}^+)}$

Triplet hinge loss:

$L(\bold{a},\bold{b}^+,\bold{b}^-)=\max{\{ 0,\cos{(\bold{a},\bold{b}^-)}+m-\cos{(\bold{a},\bold{b}^+)}\}}$

Triplet logistic loss:

- $L(\bold{a},\bold{b}^+,\bold{b}^-)=\log{( 1+\exp{[\sigma·(\cos{(\bold{a},\bold{b}^-)}-\cos{(\bold{a},\bold{b}^+))}])}}$

- $\sigma$ 是大于 0 的超参数，控制损失函数的形状，需手动设置

#### Listwise 训练

一条数据包含：

- 一个用户，特征向量记作 \bold{a}
- 一个正样本，特征向量记作 \bold{b}^+
- 多个负样本，特征向量记作 \bold{b}^-_1,...,\bold{b}^-_n

鼓励$\cos{(\bold{a},\bold{b}^+)}$ 尽量大

鼓励 $\cos{(\bold{a},\bold{b}^-_1)},...,\cos{(\bold{a},\bold{b}^-_n)}$ 尽量小

<img src="https://cdn.nlark.com/yuque/0/2022/png/101969/1672042317453-2e6860cf-79ad-492a-b350-5f8115174edf.png?x-oss-process=image%2Fformat%2Cwebp" alt="img" style="zoom:50%;" />

- 正样本 $y^+=1$，即鼓励 $s^+ $趋于 1
- 负样本 $y^-_1=...=y^-_n=0$，即鼓励 $s^-_1...s^-_n$ 趋于 0
- 用 y 和 s 的交叉熵作为损失函数，意思是鼓励 Softmax 的输出 s 接近标签 y

#### 不适用于召回的模型

<img src="https://cdn.nlark.com/yuque/0/2022/png/101969/1672042317590-889ebdfc-4e88-4b03-bfd7-57e946cbdc3f.png?x-oss-process=image%2Fformat%2Cwebp" alt="img" style="zoom:50%;" />

用户和物品的向量在进入神经网络前就拼接起来了，和双塔模型有很大区别

- 双塔模型是在后期输出相似度时才进行融合
- 用户（或物品）自身特征的拼接没有影响，依然保持了用户（或物品）的独立性
- 而一旦用户和物品进行拼接，此时的输出就特定于该 用户（或物品）了

这种前期融合的模型，不适用于召回

- 因为得在召回前，把每个用户向量对应的所有物品向量挨个拼接了送入神经网络
- 假设有一亿个物品，每给用户做一次召回，就得跑一亿遍

这种模型通常用于排序，在几千个候选物品中选出几百个

以后看到这种模型就要意识到 —— 这是排序模型，不是召回模型

#### 双塔模型：正负样本

暂略

#### 双塔模型：线上召回和更新

离线存储：把物品向量 b 存入向量数据库 线上召回：查找用户最感兴趣的k个物品

为什么事先存储物品向量 b, 线上现算用户向量a?

- 每做一次召回，用到一个用户向量 a, 几亿物品向量 b（线上算物品向量的代价过大）
- 用户兴趣动态变化，而物品特征相对稳定（可以离线存储用户向量，但不利于推荐效果）

#### 模型更新

全量更新 vs 增量更新：

全量更新：今天凌晨，用昨天全天的数据训练模型

- 在昨天模型参数的基础上做训练（不是重新随机初始化）
- 用昨天的数据，训练 1 epoch，即每天数据只用一遍
- 发布新的 用户塔神经网络 和 物品向量，供线上召回使用
- 全量更新对数据流、系统的要求比较低

增量更新：做 online learning 更新模型参数

- 用户兴趣会随时发生变化
- 实时收集线上数据，做流式处理，生成 TFRecord 文件
- 对模型做 online learning，增量更新 ID Embedding 参数（不更新神经网络其他部分的参数）

- 即锁住全连接层的参数，只更新 Embedding 层的参数，这是出于工程实现的考量

- 发布用户 ID Embedding，供用户塔在线上计算用户向量

全量更新：今天凌晨，用昨天的数据训练整个神经网络，做 1 epoch 的随机梯度下降

增量更新：用实时数据训练神经网络，只更新 ID Embedding，锁住全连接层

实际的系统：

- 全量更新 & 增量更新 相结合
- 每隔几十分钟，发布最新的用户 ID Embedding，供用户塔在线上计算用户向量

# 排序